
数据库数据过大处理方案（1.分库分表 2.归档）

分库分表研究
1.分库分表：顾名思义，即把存于一个库的数据分散到多个库中，把存于一个表的数据分散到多个表中。

分库分表两种方式：
	1.垂直分割
		库：如果是表的个数过多而让数据多，可以按照功能划分，将联系密切的表切分出来放到同一个库中。
		表：如果表的字段过多，将不同的字段拆分到不同表中。
	2.水平分割
		库：以某个字段或某几个字段，按照一定规则，将一个库中的数据拆分到不同库中。
		表：同上，不过是表维度。
	这两种方式可以同时进行。

分库分表带来的问题：
	1.事务问题
	2.以前的sql需要更改，尤其是复杂的联合查询（在分库分表设计时要考虑到查询字段和查询条件）
	3.数据同步问题（怎么同步，同步过程有错漏如何处理）
	4.全局唯一id
	
目前涉及到的十张表：
						INVESTMENTS N -> 1 LOANS 
						    1	               1
						   /                    \
						  V			 V
						 N			  N  
				     COLLECTION_PLANS			REPAYMENT_PLANS
					    1				        1
					   /					 \
					  V					  V
					 N					   N																		
			     COLLECTION_RECORDS				   REPAYMENT_RECORDS
	下面四张表可以忽视，不用太在意
	PLAN_MQ_CLIENT_MSG LOAN_SEQUENCE LOANS_INFO COLLECTION_RECORD_TRANSFER
个人思路：
	先分析表结构和sql语句，了解查询要求（不一定查询了字段就用到了，具体要看代码使用）。
	尝试进行热数据和冷数据的划分。
	全局唯一id可以用数据库本身表实现（数据库锁），带来的问题是性能瓶颈，因为所有的id生成都要依赖于这个表。
	Twitter的分布式自增ID算法Snowflake
	在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。
	* 10---0000000000 0000000000 0000000000 0000000000 0 --- 00000 ---00000 ---000000000000
	在上面的字符串中，第一位为未使用（实际上也可作为long的符号位），接下来的41位为毫秒级时间，然后5位datacenter标识位，5位机器ID（并不算标识符，实际是为线程标识），然后12位该毫秒内的当前毫秒内的计数，加起来刚好64位，为一个Long型。
	这样的好处是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞（由datacenter和机器ID作区分），并且效率较高，经测试，snowflake每秒能够产生26万ID左右，完全满足需要。
